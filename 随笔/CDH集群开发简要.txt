CDH 5.7.1 安装教程：

搭建环境：centos7_x64,CDH5.7.1安装包

（0）centos7 minimal安装配置：
0 官方rpm包下载：
http://mirror.centos.org/centos/7/extras/x86_64/Packages/
http://mirror.centos.org/centos/7/os/x86_64/Packages/

1 启用网络：
首先使用root登录服务器，输入
nmcli d
发现网卡默认是处于禁用状态的，所以需要手动打开。打开网络管理器界面，再终端输入
nmtui
使用tab键进行选择，使用enter进入，这里我们选择第一个编辑网卡，然后进入网卡选择，进行选择编辑。
选择IPV4为自动，并勾选开机自动连接选项。按确认退出。
重启网络服务：
service network restart

2 打开ssh：
service sshd start

3 从远程服务器下载需要的rpm包：
mkdir /home/iscas/rpm
scp -r root@192.168.1.100:/home/local_disk/attachment/centos7_rpm/* /home/iscas/rpm/
输入远程服务器的密码之后就可以传输文件了。
需要注意的是SCP命令也依赖于SSH的授权，如果需要免密码传输，最好将远程服务器上的ssh-key复制到当前主机的文件夹下。

4 安装本地rpm包：
切换到rpm下载位置，执行：
yum -y --nogpgcheck localinstall *.rpm

5 编辑网卡设置：
nano /etc/syscofig/network-scripts/ifcfg-ens18
设置网卡为开机启动，并且根据当前的网络连接方式设置上网。

6 安装基本网络工具
yum -y install net-tools
支持ifconfig等命令的执行。

7 设置源：
备份原来的源：
cd /etc/yum.repos.d/
cp CentOS7-Base.repo CentOS7-Base.repo.bak
获取163的源：
wget http://mirrors.163.com/.help/CentOS7-Base-163.repo -O /etc/yum.repos.d/CentOS7-Base-163.repo
重新生成缓存：
yum clean all
yum makecache

8 备份当前系统为tar：可以到根目录下新建backup目录，然后挂载到一个独立的硬盘上，保证备份数据不会掉。
查看硬盘的信息，找到独立的备份硬盘：
fdisk -l
然后挂载这个硬盘到根路径的backup路径下：
cd /
mkdir backup
新建目录是因为mount没有建立挂载点的功能，挂载前必须保证路径存在。
mount /dev/sdb /backup
然后执行压缩备份脚本，使用shell来获取当前时间：
tar -zcvpf /backups/full-backup_$(date +\%Y-\%m-\%d-\%H:\%M).tar.gz / --exclude=/backup --exclude=/proc --exclude=/lost+found --exclude=/tmp --exclude=/sys --exclude=/media
进入备份路径查看：
cd /backup

9 离线安装docker执行环境：
docker官方维护的dockerEngine包可以从这儿下载：https://yum.dockerproject.org/repo/main/centos/7/Packages/
下载：
docker-engine-selinux
docker-engine
然后安装系统支持包，主要依赖：
policycoreutils-python
libtool-ltdl
其中policycoreutils-python又依赖于6个系统支持包：
audit-libs-python
checkpolicy
libcgroup
libsemanage-python
python-IPy
setools-libs
按照上述依赖关系依次安装，最后就可以执行docker安装了：
yum -y --nogpgcheck localinstall docker-engine-*.rpm
安装完毕，启动docker服务：
service docker start

ps：更新安装docker
因为docker现在还在发展阶段，有阶段性的更新带来重要改变，所以需要按照需求重新安装更新docker，一般方法为：
列出当前系统已经安装的docker包：
yum list installed | grep docker
然后使用remove来删除引擎包：
yum remove docker-engine.x86_64
yum remove docker-engine-selinux.noarch
然后本地安装最新的引擎包，但是需要注意，因为新的版本会增加依赖，最好是联网安装，这样自动下载依赖。例如docker1.20版本的安装中，CentOS中查看yum安装软件日志：
tail /var/log/yum.log
或者直接查看yum历史纪录：
yum history info
就会发现新增了对libseccomp-2.2.1-1.el7.x86_64的依赖。

10 在线安装docker执行环境：
因为centos7的docker版本太旧，建议使用在线安装docker的基础环境，然后localinstall最新的docker：
yum -y install policycoreutils-python libtool-ltdl
yum -y localinstall /home/wentao/docker-engine*.rpm

11 添加自动执行脚本：由于部署开发的需要，系统需要定时自动执行脚本来完成任务，例如Jenkins等
Linux中，周期执行的任务一般由cron这个守护进程来处理。cron读取一个或多个配置文件，这些配置文件中包含了命令行及其调用时间。cron的配置文件称为“crontab”，是“cron table”的简写。
检查并且启用cron服务：
service cron status
service cron start
然后编写自动执行脚本，新建test.cron，添加内容：
{
10,40 * * * * echo "hello~" >> /tmp/test.txt 
}
表示：每小时的10分，40分执行一个文本写入操作
保存后添加到cron的任务中：
crontab /home/wentao/timeJob/test.cron >~/log
查看定时任务是否成功：
crontab -l
会回显在test.cron中添加的任务。

在crontab文件中写入需要执行的命令和时间，该文件中每行都包括六个域，其中前五个域是指定命令被执行的时间，最后一个域是要被执行的命令。每个域之间使用空格或者制表符分隔。格式如下： 
minute hour day-of-month month-of-year day-of-week commands    
合法值为：00-59 00-23 01-31 01-12 0-6 (0 is sunday) 
除了数字还有几个特殊的符号："*"、"/"和"-"、","
{
*代表所有的取值范围内的数字
"/"代表每的意思,"/5"表示每5个单位
"-"代表从某个数字到某个数字
","分开几个离散的数字
}
注：commands 注意以下几点
	1 要是存在文件，要写绝对路径；
	2 即使是打印也不会显示在显示屏，在后台运行，最好重定向日志。

例子：添加自动执行备份的脚本
要求每天凌晨3点备份当前系统，然后凌晨5点删除其他备份只保留最近两天备份：
编写backup.cron文本：
{
# 每天凌晨3点，开始备份，需要注意需要在cron文件中对%使用转义
0 3 * * * tar -zcvpf /home/iscas/backups/full-backup_$(date +\%Y-\%m-\%d-\%H:\%M).tar.gz / --exclude=/home/iscas/backups --exclude=/proc --exclude=/lost+found --exclude=/tmp --exclude=/sys --exclude=/media >> /home/iscas/backups/${date}.log
# 每天凌晨5点，执行查找和删除操作
0 5 * * * find /backups/ -mtime +2 -name "*.*" -exec rm -Rf {} \
}
添加到cron中，开启定时任务：
crontab /home/wentao/timeJob/backup.cron > /root/log
这样会将之前的定时任务取消，执行这个任务。对于复杂的任务，可以编写脚本，然后再定时任务中执行脚本就好了。
将上述备份命令变为可执行脚本，添加到cron中去：
首先，编写一个backup.sh的脚本，内容：
{
#!/bin/bash
# full system backup

# Backup destination
backdest=/home/iscas/backups

# Labels for backup name
#pc=${HOSTNAME}
distro=${cat /etc/redhat-release}
type=full
date=$(date +\%Y-\%m-\%d-\%H-\%M)
backupfile="$backdest/$distro-$type-$date.tar.gz"

# Exclude file location
prog=${0##*/} # Program name from filename
excdir="/home/<user>/.bin/root/backup"
exclude_file="$excdir/$prog-exc.txt"

# record log
mylog=/home/iscas/backups/${date}.log

# Check if chrooted prompt.
echo -n "First chroot from a LiveCD.  Are you ready to backup? (y/n): "
read executeback

# Check if exclude file exists
if [ ! -f $exclude_file ]; then
  echo -n "No exclude file exists, continue? (y/n): "
  read continue
  if [ $continue == "n" ]; then exit; fi
fi

if [ $executeback = "y" ]; then
  # -p and --xattrs store all permissions and extended attributes. 
  # Without both of these, many programs will stop working!
  # It is safe to remove the verbose (-v) flag. If you are using a 
  # slow terminal, this can greatly speed up the backup process.
  tar --exclude-from=$exclude_file --xattrs -czpvf $backupfile /
fi
}
然后将这个脚本添加为自动执行，编辑cron文件：
{
# 每天凌晨3点，开始备份，需要注意需要在cron文件中对%使用转义
0 3 * * * bash /home/iscas/backups/full_backup.sh
# 每天凌晨5点，执行查找和删除操作
0 5 * * * find /backups/ -mtime +2 -name "*.*" -exec rm -Rf {} \
}
然后将上面这个文件，添加到cron中。
通过上述方法就可以执行更多的任务，将执行脚本和执行任务安排分离开来。

12 在windwos下使用Emacs的tramp插件和Putty远程编辑文件：
Emacs22之后默认集成了tramp，可以通过这个插件配合windows下的Putty来远程编辑文件。
需要将windows下的Putty添加到环境变量里面，然后在Emacs中打开文件：
C-c C-F
然后输入：
/protocol:user@host:path
protocol可以是ssh和ftp，因为现在使用windows下的Putty，所以是plink，然后测试命令为：
打开文件夹：
/plink:root@192.168.1.161:/home/iscas/timeJob/
打开文件：
/plink:root@192.168.1.161:/home/iscas/timeJob/test.cron
这样就可以在windows下愉快的使用emacs来编辑远程linux下的文件了，不用再安装各种编辑器了。
果然 emacs == OS 

13 远程开发和部署：
现在的开发模式采用分布式方式，用统一的版本控制来进行代码管理。现在准备将统一的代码管理和自动化生成部署集中在一起，例如使用jekins来自动进行。
对于java项目，还是要记得一个关键点：项目结构对于java非常关键，不同的java项目有不同的组织结构。而如何组织代码是java的核心，就是每一个单独的java文件都被编译为一个class包，然后用jvm来进行组织合并。
所以，从抛开IDE的角度出发，使用gradle来进行项目开发就非常的合适了。类似的自动化编译管理脚本还有cmake等等。通过这些脚本就可以方便的进行自动化的编译测试和部署了。
我们需要搭建的就是分布式的代码管理git服务器，还有自动编译部署环境jekins。
<0>基础知识：
Git可以使用四种主要的协议来传输数据：本地传输，SSH 协议，Git 协议和 HTTP 协议。除了 HTTP 协议外，其他所有协议都要求在服务器端安装并运行 Git。
(a)

Git可以以两种主要的方式跨越两个仓库传输数据：基于HTTP协议之上，和 file://, ssh://, 和 git:// 等智能传输协议。
(a)git 基于HTTP之上传输通常被称为哑协议，这是因为它在服务端不需要有针对 Git 特有的代码。这个获取过程仅仅是一系列GET请求，客户端可以假定服务端的Git仓库中的布局。


<1>安装git服务：
安装git，以及相关的包：
yum -y install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel
yum -y install git
创建一个git用户，用来运行git服务：
groupadd git
adduser git -g git
对这个新增的用户添加密码：
passwd git
输入密码，确认。
<2>建立ssh连接密码：
SSH 也是唯一一个同时支持读写操作的网络协议。所以我们使用这个协议搭建GIT服务器。创建SSH的公钥：
su git
ssh-keygen -t rsa
默认回车，生成/home/git/.ssh/id_rsa.pub，然后在其中添加需要ssh过来的客户端密钥，一行一个：
cd /home/git/.ssh
cp id_ras.pub authorized_keys
touch authorized_keys
更改权限：
chmod 600 .ssh/authorized_keys
<3>在git服务器上建立总仓库：
在git用户的路径下新建一个文件夹作为总的仓库：
cd /home/git/
mkdir gitrepo
然后将这个文件夹的权限赋予git用户：
chown git:git gitrepo/
<4>新建一个仓库测试：
使用git用户权限，进入gitrepo文件夹下，创建一个裸仓库：
cd gitrepo
git init --bare testGitServer.git
然后在客户端尝试clone这个新的项目：
git clone  git@192.168.1.161:/home/gitrepo/testGitServer.git
然后就可以将这个空的仓库同步下来，通过执行添加就可以使用这个git仓库了。
<5>从别的仓库移植到当前仓库：
测试成功之后就可以将现在的git仓库移植到这个新的git服务器了：
首先将原来的git仓库克隆到本地：
git clone remote_GIT_URL
然后再git服务器上创建一个新的空仓库：
git init --bare DataSong.git
然后在当前克隆仓库下执行：
"c:\Program Files (x86)\Git\bin\git.exe" push --mirror git@192.168.1.161:/home/gitrepo/DataSong.git
这下就完成了不同git仓库之间的切换，并且保证了之前的版本记录。
<6>不同仓库之间的同步备份：
建立不同的同步仓库相当于备份，而且方便使用。
首先在自己的git服务器上建立一个同名的空仓库，例如test：
git init --bare test.git
然后使用命令来进行远程克隆：
git clone --mirror ssh://git@A/path/test.git
这时我们自己的服务器上就有了一份跟机器A一模一样的git仓库了。然后在自己的服务器上配置一个cron，时不时地从机器A上同步一下就行了：
git --git-dir=/dir/test.git remote update
PS：问题在于这两个git仓库服务器之间可以互相联通。
<7>禁用 shell 登录：
出于安全考虑，你可以用 Git 自带的 git-shell 工具限制 git 用户的活动范围。这可以通过编辑 /etc/passwd 文件完成。找到类似下面的一行：
把 bin/sh 改为 /usr/bin/git-shell （或者用 which git-shell 查看它的实际安装路径）
git:x:1001:1001::/home/git:/bin/bash
改为：
git:x:1001:1001::/home/git:/bin/git-shell
因为服务器上的 Git 仓库是为了共享，所以不让用户直接登录到服务器上去改工作区。
<8>公共匿名访问GIT服务器：
匿名的读取权限该怎么实现呢？也许除了内部私有的项目之外，你还需要托管一些开源项目。或者因为要用一些自动化的服务器来进行编译，或者有一些经常变化的服务器群组，而又不想整天生成新的 SSH 密钥 — 总之，你需要简单的匿名读取权限。
在centos7下面搭建HTTP协议的GIT服务，需要使用apache。查看当前apache的版本：
rpm -qa | grep httpd
返回
httpd-tools-2.4.6-40.el7.centos.1.x86_64
httpd-2.4.6-40.el7.centos.1.x86_64
或者httpd -v：
Server version: Apache/2.4.6 (CentOS)
Server built:   May 12 2016 10:27:23
所以centos7默认安装了2.4.6版本的apache。
创建由apache管理的用于git用户验证的帐户（用户帐户）：
htpasswd -m -c /etc/httpd/conf.d/git-team.htpasswd <username>
然后输入该用户要使用的密码。
修改git-team.htpasswd文件的所有者与所属群组：
chown git:git /etc/httpd/conf.d/git-team.htpasswd
设置git-team.htpasswd文件的访问权限：
chmod 640 /etc/httpd/conf.d/git-team.htpasswd
修改apache配置文件httpd.conf：
nano /etc/httpd/conf/httpd.conf
在结尾添加如下内容：
{
<VirtualHost *:80>
        ServerName git.hellmonky.com
        SetEnv GIT_HTTP_EXPORT_ALL
        SetEnv GIT_PROJECT_ROOT /home/git/gitrepo
        ScriptAlias /git/ /usr/libexec/git-core/git-http-backend/
        <Location />
                AuthType Basic
                AuthName "Git"
                AuthUserFile /etc/httpd/conf.d/git-team.htpasswd
                Require valid-user
        </Location>
</VirtualHost>
}
其中：
{
ServerName是git服务器的域名
/home/git/gitrepo是代码库存放的文件夹
ScriptAlias是将以/git/开头的访问路径映射至git的CGI程序git-http-backend
AuthUserFile是验证用户帐户的文件
}
保存后退出，重启httpd服务。然后就可以访问了：
git clone http://git.hellmonky.com/git/testGitServer
输入用户名与密码，如果输出下面的信息，就说明签出成功。
<9>权限管理：
通过ssh的方式进行代码上传和下载需要使用git用户的密码，或者使用authorized_keys来进行授权。当用户数量达到几百人的规模时，管理起来就会十分痛苦。每次改删用户都必须登录服务器不去说，这种做法还缺少必要的权限管理。应该使用权限管理的方式进行更为细致的服务。例如Gitosis。
Gitosis 就是一套用来管理 authorized_keys 文件和实现简单连接限制的脚本。有趣的是，用来添加用户和设定权限的并非通过网页程序，而只是管理一个特殊的 Git 仓库。你只需要在这个特殊仓库内做好相应的设定，然后推送到服务器上，Gitosis 就会随之改变运行策略。

上述整个过程可以通过docker的形式进行打包发布。

参考教程：
https://git-scm.com/book/zh/v1/Git-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE
https://git-scm.com/book/zh/v1/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84-Git-%E5%8D%8F%E8%AE%AE
http://wlog.cn/soft/git-ssh-server-for-debian.html
http://www.open-open.com/lib/view/open1328069988843.html
http://www.cnblogs.com/dudu/archive/2012/12/09/linux-apache-git.html




（1）基础环境搭建：
1 主机名称修改：
hostnamectl set-hostname master
hostname 查看

2 host配置：
使用文本编辑器
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.1.200 master
192.168.1.201 slave01
192.168.1.202 slave02
192.168.1.203 slave03
192.168.1.204 slave04
192.168.1.205 slave05
192.168.1.206 slave06
192.168.1.207 slave07
192.168.1.208 slave08
192.168.1.209 slave09
192.168.1.210 slave10
192.168.1.211 slave11

3 关闭防火墙：
sudo systemctl stop firewalld.service
关闭开机启动：
sudo systemctl disable firewalld.service

4 关闭selinux：
nano /etc/selinux/config
设置其中的
SELINUX=disabled
退出后
setenforce 0
立即生效

5 开机启动联网：
/etc/sysconfig/network-scripts/ifcfg-eno1
设置其中的ONBOOT=yes

6 生成ssh密钥
ssh-keygen -t rsa
一路回车直到结束，然后切换到/root/.ssh下对公钥重命名
cat id_rsa.pub >authorized_keys
修改公钥权限：
chmod 600 authorized_keys
将authorized_keys从master分发到各个slave：
scp /root/.ssh/authorized_keys root@slave01:/root/.ssh/

7 安装oracle的jdk：
rpm -qa |grep java
rpm -qa |grep jdk
yum remove java*(删除自带的java)
安装JDK的rpm包：
rpm -ivh jdk1.7.0_67.rpm
设置环境变量：
nano /etc/profile
添加以下内容：
export JAVA_HOME=/usr/java/jdk1.8.0_92
export CLASSPATH=.:$CLASSPTAH:$JAVA_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin
环境变量生效：
source /etc/profile

8 卸载默认安装的mysql
rpm -qa | grep mariadb
rpm -e --nodeps mariadb-libs-5.5.41-2.el7_0.x86_64
注意：如果默认自带的mysql不卸载会包数据库连接错误，安装失败，删除配置文件之后重新安装也是可以的。

上述步骤完毕之后备份虚拟机，方便后续搭建CDH集群。



（2）主节点安装cm：
1 添加repo：
wget https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo -O /home
cp cloudera-manager.repo /etc/yum.repos.d/
通过下面的命令检查是添加了对应版本的源
yum list|grep cloudera
然后更新一下源
yum -y update

2 安装rpm包：
安装如下的包：
cloudera-manager-agent-5.7.1-1.cm571.p0.8.el7.x86_64.rpm
cloudera-manager-daemons-5.7.1-1.cm571.p0.8.el7.x86_64.rpm
cloudera-manager-server-5.7.1-1.cm571.p0.8.el7.x86_64.rpm
cloudera-manager-server-db-2-5.7.1-1.cm571.p0.8.el7.x86_64.rpm
enterprise-debuginfo-5.7.1-1.cm571.p0.8.el7.x86_64.rpm
oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm

3 拷贝资源包到目标目录
将下面的三个文件拷贝到目录：
CDH-5.7.1-1.cdh5.7.1.p0.11-el7.parcel
CDH-5.7.1-1.cdh5.7.1.p0.11-el7.parcel.sha
manifest.json
执行：
cp * /opt/cloudera/parcel-repo/

4 安装CM

chmod a+x cloudera-manager-installer.bin
如果没有错就表示当前的CM安装已经完毕了，访问：
localhost:7180
进入web界面进行CM的安装管理

（3）安装集群
添加包含主节点在内的所有节点的IP地址，然后默认安装就好了。

（4）安装kafka
参考文档：
http://www.cnblogs.com/jechedo/p/5122531.html


（5）在namenode节点管理HDFS
su hdfs
hadoop fs -mkdir /user/DMDD
hadoop fs -chown root /user/DMDD
hadoop fs -chmod 777 /user/DMDD
清空文件夹：要求文件夹一定是空的
hadoop fs -rmdir /user/DMDD/

（6）运行CDH的HDFS基准测试：
输入：
ls /opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop* | egrep "examples|test"
返回：
/opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-examples-2.6.0-mr1-cdh5.7.1.jar
/opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-examples.jar
/opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-examples-mr1.jar
/opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-test-2.6.0-mr1-cdh5.7.1.jar
/opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-test-mr1.jar

然后选择其中的hadoop-test-mr1.jar，来执行TestDFSIO write测试：
su hdfs
进入管理员权限

向HDFS中写入10个1000MB的文件：
hadoop jar /opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-test-mr1.jar TestDFSIO -write -nrFiles 10 -fileSize 1000
从HDFS中读取10个1000MB的文件：
hadoop jar /opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-test-mr1.jar TestDFSIO -read -nrFiles 10 -fileSize 1000
清空测试数据：
hadoop jar /opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hadoop-0.20-mapreduce/hadoop-test-mr1.jar TestDFSIO -clean


（7）mapreduce程序开发：
使用hadoop的主要因素就是可以使用分布式的处理系统，现在开发流程为：

IDEA开发gradle工程的一般过程：
1 ：编写gradle脚本，添加基本的构建过程；
2 ：在当前gradle脚本所在文件夹下执行：gradle build 命令生成基本工程文件；
3 ：打开IDEA导入当前生成的工程文件，执行生成目录结果的task或者手动建立对应的文件夹；
4 ：根据自己的工程组建package结构，然后添加对应的代码进行开发。

MapReduce程序开发可以遵循以下流程。
第一步：清楚问题是什么，确定解决问题的算法思路。
第二步：设计和实现mapreduce程序中的Mapper。
第三步：设计和实现mapreduce程序中的Reducer。
第四步：设置作业调度。
mapreduce程序与很多编程有所不同，它是一种函数型编程，完全地展现了“分而治之”的哲学思想，是分布式系统下一种强有力的处理工具。

mapreduce开发具体流程：


（8）大文件上传技术：
http://blog.kazaff.me/2014/11/14/%E8%81%8A%E8%81%8A%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/

（9）在线视频播放技术：
https://github.com/yeleaveszi/Play-Videos-In-HDFS
后端使用HDFS作为文件存储服务器，用于大文件的分布式存储。

关于直播相关的内容，在互联网和内网的状况是非常不一样的：
<1>互联网考虑不同CDN来进行加速和缓存的问题，内网基本是直连网络不需要太过于考虑不同节点的加速功能；
<2>

（10）前端开发思考：
https://github.com/fouber/blog/issues/1
https://github.com/fouber/blog/issues/2
对于前台开发的一些内容进行思考和整理，从深圳的Spring物流开发工程来进行重新整理。

使用fis3来完成前端工程的打包和发布。

（11）数据可视化相关的前台展示：
使用D3.js作为前台的数据可视化展示插件来进行开发，效果比较统一。
官方地址：
https://d3js.org/
中文教程：
http://www.ourd3js.com/wordpress/?p=396


（12）关于KVM虚拟化相关的资料：
传统的vmware虚拟化和之后出现的KVM虚拟化，以及未来发展方向的openstack，从不同层面上展示了虚拟化的应用发展流程。
KVM一般是指linux-kernel的内存和cpu虚拟化+qemu的上层硬件虚拟化；
openstack通过libvir来进行上层的统一管理，提供web端的管理等。

（13）阅读Hadoop源代码的一些感想：
自己的java水平很低，一些常见的编程方式和不良习惯都有，从C到java的这一路过来都很不专业，自己的知识和能力水平需要本质的提升；
ConcurrentHashMap这个类是java为多线程访问而设置的map结构，

（14）关于proxmox主机网卡的设置：
命令：
ethtool -s eth0 autoneg off speed 1000 duplex full
需要在主机重启，然后生效。
KVM虚拟机可以使用虚拟，半虚拟已经直连的方式来和物理网卡桥接，网速影响比较小。
参考文档：
http://www.cnblogs.com/gergro/archive/2008/09/17/1292730.html
http://zhuyong1985.blog.51cto.com/2118260/1094455
http://www.92cto.com/blog/369.html


思考：关于服务器多网卡的使用
多个网卡可以接不同的网络来保证走不同的流量，也可以做bonding来做链路聚合进行负载均衡。
在linux2.4之后的内核中已经支持了，查看当前主机是否支持：
cat /boot/config-4.2.6-1-pve |grep -i CONFIG_BONDING
回显：
CONFIG_BONDING=m
表示支持。
现在准备设置

参考文档：
http://lansgg.blog.51cto.com/5675165/1680219

（15）HDFS结合RAID:
传统的HDFS存储默认需要3份备份，这种存储模式虽然非常保险，但是对于空间的消耗巨大；参考多盘系统的RAID方式进行改进的想法也提出来了，facebook维护并且开源实现了这种想法，官方地址为：
https://github.com/facebookarchive/hadoop-20
但是显示官方已经不在维护了。官方对于停止维护给出了一个文档来说明这个过程：
https://code.facebook.com/posts/536638663113101/saving-capacity-with-hdfs-raid/
总体上就是说，这种方式并没有达到预期的空间节省，用户上传的“小文件”并不足以满足这种raid提升空间利用率的要求。并且在PB级别的数据时候遇到了很多部署问题。
最后的结论就是考虑到开发中和应用场景的关联，部署的难度，facebook已经放弃了这种在HDFS中使用RAID的方式来节省空间，还是继续采用3备份来保证数据的安全和稳定性。


参考文档：
http://jiangbo.me/blog/2013/06/05/setup-hdfs-raid/





（16）关于ubuntu server安装完毕之后的初始设置：以ubuntu16.04为例
设置root用户密码的命令：sudo passwd root 
然后还要安装ssh来供外部链接：
apt-get install openssh-server
然后检查状态并且设置可以用root连接ssh：
service ssh status
nano /etc/ssh/sshd_config
将行：
PermitRootLogin prohibit-password
StrictModes yes
注释，下面添加一行：
PermitRootLogin yes
重启ssh服务：
systemctl restart sshd

安装基本的编译环境：
apt-get install build-essential git
安装编辑器
apt-get install vim
然后编辑源列表：
vim /etc/apt/source.list
使用vim:dG删除全部，:wq保存退出
nano /etc/apt/source.list
添加一下内容：
{
deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse
deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse
deb http://cn.archive.ubuntu.com/ubuntu/ xenial-updates main restricted universe multiverse
deb http://cn.archive.ubuntu.com/ubuntu/ xenial-backports main restricted universe multiverse
##测试版源
deb http://cn.archive.ubuntu.com/ubuntu/ xenial-proposed main restricted universe multiverse
# 源码
deb-src http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse
deb-src http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse
deb-src http://cn.archive.ubuntu.com/ubuntu/ xenial-updates main restricted universe multiverse
deb-src http://cn.archive.ubuntu.com/ubuntu/ xenial-backports main restricted universe multiverse
##测试版源
deb-src http://cn.archive.ubuntu.com/ubuntu/ xenial-proposed main restricted universe multiverse
# Canonical 合作伙伴和附加
deb http://archive.canonical.com/ubuntu/ xenial partner
deb http://extras.ubuntu.com/ubuntu/ xenial main
}
保存退出，apt-get update
安装kernel编译依赖：
apt-get build-dep linux

安装jdk
下载oracle的jdk版本，scp到ubunt的目录下，然后解压：
tar -zxvf /home/wentao/jdk-8u92-linux-x64.tar.gz -C /usr/local/bin/
添加系统环境变量：
nano /etc/profile
添加以下内容：
{
export JAVA_HOME=/usr/local/bin/jdk1.8.0_92
export JRE_HOME=/usr/local/java/jdk1.6.0_30/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$JAVA_HOME:$PATH
}
保存后执行命令生效：
source /etc/profile
检查jdk安装是否成功：
java -version

输入：
du  –h  /var/cache/apt/archives
查看apt-get的缓存文件，然后执行清理：
apt-get clean
apt-get autoclean
apt-get autoremove

输入：
dpkg --get-selections | grep linux
检查当前安装的内核版本。然后删除旧的内核：
apt-get purge  内核文件名  头文件名


（17）关于虚拟化的更进一步思考：
当前不论是使用vmware还是proxmox类似的KVM虚拟机，都需要搭建一个完整的linux环境来运行服务，这对于系统的压力是比较大的， 所以可以考虑，只运行必要的服务来减少压力，所以进入了docker来进行尝试。
Docker 容器在运行时与虚拟机（VM）的运行有很大的区别， Docker容器与宿主机共享同一个操作系统，不会有额外的操作系统开销。这样的优势很明显，因而大大提高了资源利用率，并且提升了 I/O 等方面的性能。
所以对于docker镜像的生成一定要把握住这一点，不要求完整的运行环境，应该是一个附加在当前系统的独立的运行环境。

<1>使用脚本生成镜像：
对于自己的需求比较特使的，可以使用自定义制作docker镜像，官方教程为：
https://docs.docker.com/engine/articles/baseimages/
也可以参考国内的资料：
http://www.cnblogs.com/2018/p/4633940.html
在centos7内执行：
wget https://raw.githubusercontent.com/docker/docker/master/contrib/mkimage-yum.sh -O /home/wentao/mkimage-yum.sh
cd /home/wentao
chmod 777 mkimage-yum.sh
./mkimage-yum.sh -y /etc/yum.conf centos7
这个脚本的主要执行过程为：
1．tmp目录下建立临时目录和文件系统
2．使用yum安装相关的软件包
3．软件包安装和信息定制
4．tar打包
5．清理

<2>使用官方tar方法生成docker镜像：
使用 Tar 创建 Docker 基本映像：
对于ubuntu系统为例来制作基础镜像：
首先安装基本的docker运行环境：
sudo apt-get install docker.io debootstrap
然后开始创建一个镜像：
sudo debootstrap hellmonky hellmonky > /dev/null
sudo tar -C hellmonky -c . | sudo docker import - hellmonky
其中
1. docker.io用来创建docker的运行环境；debootstrap是官方提供的，用来获取构建基本docker镜像需要的包；
2. ”sudo debootstrap hellmonky hellmonky > /dev/null“，当前文件夹创建了一个 tar 文件并输出到标准输出中；
3. "docker import - hellmonky" 通过管道从标准输入中获取这个 tar 文件并根据它创建一个名为 hellmonky 的基本映像。
上述命令执行成功，但是运行之后没有任何的可执行程序。无法完成任何的功能。

<3>使用系统备份tar包的方式来构建一个docker镜像：
首先是备份当前的系统为一个tar包：
tar -cvf /home/wentao/system.tar / --exclude=/proc --exclude=/lost+found --exclude=/tmp --exclude=/sys --exclude=/media --exclude=/home
然后切换到当前tar包所在目录，导入为docker镜像：
cat system.tar | sudo docker import - full_ubuntu
导入成功之后查看docker镜像：
docker images
查看这个docker的标签：
docker run -i -t full_ubuntu cat /etc/lsb-release
然后运行这个docker镜像：
docker run -t -i full_ubuntu /bin/bash
执行完毕之后输入
exit
来退出docker环境，然后可以使用下面的命令将docker镜像导出为一个tar包：
docker save -o /home/wentao/ubuntu1604Docker.tar full_ubuntu

<4>使用官方提供的boot.iso构造docker镜像：
官方的安装教程：https://github.com/CentOS/sig-cloud-instance-build/tree/master/docker
针对centos7，官方提供了一个基本的可引导镜像：
http://mirror.centos.org/centos/7/os/x86_64/images/boot.iso
来作为docker镜像的生成基础：
livemedia-creator 工具是 lorax 软件包的一部分，所以首先安装lorax：
yum -y install lorax
lorax 之外还需要安装其他几个软件包。这些软件包不是 lorax 的相依性软件包，因此不会自动安装，但您可能会需要他们，具体要看您使用 livemedia-creator 要做什么。这些软件包为：
{
virt-install：提供构建新虚拟机的软件包，除非指定 --no-virt 选项，否则会在生成 live 介质的第一阶段使用这个软件包。
libvirt、qemu-kvm、virsh 和其他虚拟化工具：使用 virt-install 时，必须让系统准备好生成、运行并管理虚拟机。有关 Red Hat Enterprise Linux 中虚拟化的信息以及安装及使用虚拟化工具的文档，请查看《Red Hat Enterprise Linux 7 虚拟化部署及管理指南》。
anaconda： Red Hat Enterprise Linux 安装程序，如果使用 --no-virt 选项，则在第一阶段使用，而不是在 virt-install 中使用。
}
参考：https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Installation_Guide/sect-disk-image-installation-automatic.html
选择安装：
yum -y install virt-install 
还需要安装：
yum -y install libvirt-daemon-config-network
否则会提示：Failed to connect socket to '/var/run/libvirt/libvirt-sock': No such file or directory
重启libvirtd服务：
service libvirtd start
然后就可以使用livemedia-creator来从可引导的iso制作rootfs：
sudo livemedia-creator --make-tar --iso=/path/to/boot7.iso --ks=/path/to/centos-7.ks --image-name=centos-7-docker.tar.xz
这样就生成了当前使用的tar.xz包。
PS:在vmware虚拟机中上述操作失败，因为权限问题，参考：https://www.brianlane.com/creating-live-isos-with-livemedia-creator.html
需要将当前文件路径的权限修改：
chmod a+x /
建议直接下载做好的rootfs的tar包进行下面的操作生成镜像。
然后使用tar包导入的方式来生成docker镜像，新建文件夹centos7_base，然后将上述tar.xz包和下面内容的Dockerfile保存：
{
FROM scratch
MAINTAINER https://github.com/CentOS/sig-cloud-instance-images
ADD centos-7-docker.tar.xz /

LABEL name="CentOS Base Image" \
    vendor="CentOS" \
    license="GPLv2" \
    build-date="20160701"

CMD ["/bin/bash"]
}
然后切换到上级目录，输入：
docker build -t centos7_base centos7_base/
执行完毕就可以查看当前的导入状况了：
docker images
可以看到这个镜像比之前的tar.xz还要小，这个就是docker镜像的复用机制起了作用。然后就可以导入并且运行这个docker镜像了：
docker run -t -i centos7_base /bin/bash
输入：
docker save -o /home/iscas/centos7_base.tar centos7_base
保存当前生成的镜像，下次直接用来导入，不用再进行生成工作了。


<5>查看当前的dockerImage的层次结构：
docker history full_ubuntu
获取结果为生成这个system的历史记录，每一个记录都表示一个层：
{}
Docker 镜像层的内容一般在 Docker 根目录的 aufs 路径下，为 /var/lib/docker/aufs/diff/，切换到这个目录下，然后输入：
ls | xargs ls
结果如下：
{}
对于每一个镜像层，Docker 都会保存一份相应的 json 文件，json 文件的存储路径为 /var/lib/docker/graph，切换到这个目录，然后查看：
ls | xargs ls
结果如下：
{}
除了 json 文件，每一个镜像层还包含一个 layersize文件，该文件主要记录镜像层内部文件内容的总大小：
cat json
结果如下：
{}

<6>删除标签为<none>的镜像：
当创建docker镜像失败的时候，会生成tag为<none>的缓存文件，需要使用如下命令进行删除：
docker rmi -f $(docker images | awk '/^<none>/ { print $3 }')



PS：关于之后生成的docker镜像，参考了：
http://stackoverflow.com/questions/19234831/where-are-docker-images-stored-on-the-host-machine
或者在/var/lib/docker/文件夹下使用按照大小排序的方式查看：
ls -Sl -R /var/lib/docker/ | less
和上述文档中描述的结果大体相同，在本地不是以一个文件的形式存在，而是以一个文件夹的形式存在。通用形式为tar包。
生成完毕之后可以尝试运行：
sudo docker run hellmonky cat /etc/lsb-release
但是这种tar包的docker制作，最终结果非常大，不能实际运行，所以需要用其他方式来生成必要服务的镜像。


（18）Dockerfile构造自定义镜像：
接着17的内容，从tar包创建docker镜像存在比较大的问题，一般而言，为了方便使用者都是用已有的镜像进行修改来到达定制的目的。
广泛采用的方法就是用Dockerfile和资源文件来进行dockerImage的创建。
<1>当前状态检查：
检查当前的docker版本：
docker version
返回：
{
Client:
 Version:         1.10.3
 API version:     1.22
 Package version: docker-common-1.10.3-44.el7.centos.x86_64
 Go version:      go1.4.2
 Git commit:      9419b24-unsupported
 Built:           Fri Jun 24 12:09:49 2016
 OS/Arch:         linux/amd64

Server:
 Version:         1.10.3
 API version:     1.22
 Package version: docker-common-1.10.3-44.el7.centos.x86_64
 Go version:      go1.4.2
 Git commit:      9419b24-unsupported
 Built:           Fri Jun 24 12:09:49 2016
 OS/Arch:         linux/amd64
}
然后查看当前的docker状态：
docker info
返回结果为：
{
Containers: 0
 Running: 0
 Paused: 0
 Stopped: 0
Images: 0
Server Version: 1.11.2
Storage Driver: aufs
 Root Dir: /var/lib/docker/aufs
 Backing Filesystem: extfs
 Dirs: 0
 Dirperm1 Supported: true
Logging Driver: json-file
Cgroup Driver: cgroupfs
Plugins: 
 Volume: local
 Network: null host bridge
Kernel Version: 4.4.0-21-generic
Operating System: Ubuntu 16.04 LTS
OSType: linux
Architecture: x86_64
CPUs: 4
Total Memory: 1.937 GiB
Name: ubuntu
ID: BTUW:2NU5:ZIWM:7MDE:RQAR:FBFB:QPJ2:IYI6:GKHR:QFWO:7SOE:OW23
Docker Root Dir: /var/lib/docker
Debug mode (client): false
Debug mode (server): false
Registry: https://index.docker.io/v1/
WARNING: No swap limit support
}
<2>准备生成镜像的基本资源：
首先创建一个文件夹，这个文件夹下面包含需要的资源：
{
DataSong.jar：要部署的应用
Dockerfile：描述容器的文件
jdk-8u92-linux-x64.tar.gz：要在容器里安装的java版本
}
然后编写Dockerfile内容为：
{
# setup build base image
FROM centos7_base

# setup builder info
MAINTAINER hellmonky <hellmonky@qq.com> 

# setup Java 
RUN mkdir /opt/java
COPY jdk-8u92-linux-x64.tar.gz /opt/java/ 

# change dir to Java installation dir 
WORKDIR /opt/java/ 
RUN tar -zxf jdk-8u92-linux-x64.tar.gz -C /usr/local/bin/

#setup environment variables, 使用update-alternatives的install命令增加一组新的系统命令链接符，这儿就是java，100表示优先级
RUN update-alternatives --install /usr/bin/javac javac /usr/local/bin/jdk1.8.0_92/bin/javac 100
RUN update-alternatives --install /usr/bin/java java /usr/local/bin/jdk1.8.0_92/bin/java 100
RUN update-alternatives --display java
RUN java -version

#delete jdk package，但是通过docker history 发现，这一步并没减少磁盘容量，不清楚是什么情况
RUN rm /opt/java/jdk-8u92-linux-x64.tar.gz

#setup Jar package
COPY DataSong.jar /opt/java/

#Expose the ports we're interested in，这个是tomcat，所以需要开8080端口等
EXPOSE 8080 9990 

#Set the default command to run on boot, This will boot WildFly in the standalone mode and bind to all interface 
#CMD ["/opt/wildfly/bin/standalone.sh", "-c", "standalone-full.xml", "-b", "0.0.0.0"]
CMD ["java", "-jar", "/opt/java/DataSong.jar"]
}
然后切换包含Dockerfile的父目录运行以下命令：
docker build -t datasong dataSong/
检查执行情况：
docker history datasong
然后开始运行这个docker：
docker run -t -i datasong /bin/bash

<3>开放docker镜像端口，供外部调用：
需要注意的就是启动的docker如果需要通过端口提供服务，就一定需要将docker和主机进行通信设置，否则相当于封闭环境。虽然在<2>中成功的运行了docker，但是外部无法访问datasong提供的服务，所以需要进行设置。
首先查看当前docker镜像的信息：
docker inspect <container_id>
那么就是：
docker inspect datasong
在Dockfile中使用EXPOSE表明需要暴露的端口，那么就需要将docker镜像的端口绑定到主机的指定接口，语法为：
docker run -p [([<host_interface>:[host_port]])|(<host_port>):]<container_port>[/udp] <image> <cmd>
所以使用如下命令打开端口：
docker run -i -t -p 8080:8080 datasong
-p指定容器端口到主机端口的映射，表示使用主机的8080端口，对应到docker的8080端口。然后从外部进行访问。
我们可以实例化多个容器，因为它们的端口在宿主上不会发生冲突。我将再启动两个容器并将8080端口分别暴露为8280和8380：
docker -H tcp://127.0.0.1:2375 run -p 8280:8080 javaee_sample 
docker -H tcp://127.0.0.1:2375 run -p 8380:8080 javaee_sample 

<4>docker镜像中如果层数过多会带来性能问题，那么在编写Dockfile的时候尽量减少不必要的步骤：
例如可以将需要的资源直接拷贝到已有地址，提前解压缩等等。
修改后的脚本如下：
{
# 设置基本的环境
FROM centos7_base
MAINTAINER hellmonky <hellmonky@qq.com> 

# 创建目录，从主机拷贝需要的文件，需要注意解压后的目录拷贝到docker中，需要指明这个文件夹的名称，否则为文件拷贝
COPY jdk1.8.0_92 /usr/local/bin/jdk1.8.0_92/

# 设置环境变量
ENV JAVA_HOME=/usr/local/bin/jdk1.8.0_92
ENV CLASSPATH=.:$CLASSPTAH:$JAVA_HOME/lib
ENV PATH=$PATH:$JAVA_HOME/bin

# 拷贝运行包
COPY DataSong.jar /home

# 需要对外开放的端口 
EXPOSE 8080 9990 

# 设置docker启动时候需要执行的命令
CMD ["java", "-jar", "/opt/java/DataSong.jar"]
}
这样生成的镜像少了jdk-8u92-linux-x64.tar.gz所占用的空间，利用率更高。

关于Dockfile的CMD命令，参考官方文档：
https://docs.docker.com/engine/reference/builder/#cmd
参考文档：
http://cloud.51cto.com/art/201501/464181.htm
<5>运行和进入容器：
直接使用：
docker run -it datasong /bin/bash
命令行会直接进入这个容器，如果需要守护状态的容器，可以使用-d命令：
docker run -itd datasong /bin/bash 
这样容器会在后台执行，命令行并不会进入。
可以查看当前运行中的容器：
docker ps
然后使用attach命令选中想要进入运行中的容器的CONTAINER ID：
docker attach 44fc0f0582d9
这样虽然方便，但是不同命令行进入容器会造成阻塞，而且不建议使用ssh到容器中：http://blog.docker.com/tag/nsenter/
译文：http://www.oschina.net/translate/why-you-dont-need-to-run-sshd-in-docker?cmp
所以需要使用nsenter来对后台运行的容器进行管理。
首先需要在linux官方下载源代码包，从 https://www.kernel.org/pub/linux/utils/util-linux/ 找到最新的版本，然后下载：
wget https://www.kernel.org/pub/linux/utils/util-linux/v2.28/util-linux-2.28-rc1.tar.gz
然后编译安装（编译需要gcc和make的支持，可以在docker容器中进行编译）：
tar -zxvf util-linux-2.28.tar.gz
cd util-linux-2.28
./configure --without-ncurses && make nsenter
cp nsenter /usr/local/bin
nsenter可以访问另一个进程的名称空间。所以为了连接到某个容器我们还需要获取该容器的第一个进程的PID。
使用docker inspect命令来拿到该PID：
docker inspect 258e36aeb1ee
这样返回了所有的信息，而我们目前只需要PID信息，可以使用下属命令获取：
docker inspect -f {{.State.Pid}} 258e36aeb1ee
拿到该进程PID之后我们就可以使用nsenter命令访问该容器了：
nsenter --target 30229 --mount --uts --ipc --net --pid
其中30229就是刚刚获取的PID。
为了简化这个步骤，可以编写脚本来完成：
nano docker-enter.sh
{
#!/bin/sh
 
  if [ -e $(dirname "$0")/nsenter ]; then
    # with boot2docker, nsenter is not in the PATH but it is in the same folder
    NSENTER=$(dirname "$0")/nsenter
  else
    NSENTER=nsenter
  fi
 
  if [ -z "$1" ]; then
    echo "Usage: `basename "$0"` CONTAINER [COMMAND [ARG]...]"
    echo ""
    echo "Enters the Docker CONTAINER and executes the specified COMMAND."
    echo "If COMMAND is not specified, runs an interactive shell in CONTAINER."
  else
    PID=$(docker inspect --format "{{.State.Pid}}" "$1")
    if [ -z "$PID" ]; then
      exit 1
    fi
    shift
 
    OPTS="--target $PID --mount --uts --ipc --net --pid --"
 
    if [ -z "$1" ]; then
      # No command given.
      # Use su to clear all host environment variables except for TERM,
      # initialize the environment variables HOME, SHELL, USER, LOGNAME, PATH,
      # and start a login shell.
      "$NSENTER" $OPTS su - root
    else
      # Use env to clear all host environment variables.
      "$NSENTER" $OPTS env --ignore-environment -- "$@"
    fi
  fi
}
保存后设置权限为可执行，然后拷贝到/usr/bin目录下可执行：
chmod +x docker-enter  && cp docker-enter  /usr/bin/
这样就可以直接使用docker镜像的ID来进入容器了：
docker-enter 258e36aeb1ee
上述方法比较繁琐，docker 1.3版本之后提供了exec命令来简化进入docker容器的方式：
docker exec -it 258e36aeb1ee /bin/bash
其中258e36aeb1ee是docker ps获取的运行容器的ID，不再需要执行容器的进程的PID了。
参考文档：
http://blog.csdn.net/u010397369/article/details/41045251
http://www.roddypy.com/index.php/2015/11/27/%E4%BD%BF%E7%94%A8nsenter%E8%BF%9B%E5%85%A5docker%E5%AE%B9%E5%99%A8/


（19）在docker中使用磁盘空间存储：
首先需要明确的就是：不要在 container 里存放永久性数据，contain类似于静态的，无法处理需要固化的数据。
但是实际使用场景中需要在contain中去操作文件等，类似于mysql数据库，是需要将动态数据固化的。
保持容器为静态并且可以有持久化机制的方式可以有：挂载主机目录和使用数据卷。
<1>在docker中挂载主机目录：

<2>使用数据卷:
然后看看docker的镜像结构：
Docker镜像是由多个文件系统（只读层）叠加而成。当我们启动一个容器的时候，Docker会加载只读镜像层并在其上（也就是镜像栈顶部）添加一个读写层。如果运行中的容器修改了现有的一个已经存在的文件，那该文件将会从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在，只是已经被读写层中该文件的副本所隐藏。当删除Docker容器，并通过该镜像重新启动时，之前的更改将会丢失。在Docker中，只读层及在顶部的读写层的组合被称为Union File System（联合文件系统）。
为了能够保存（持久化）数据以及共享容器间的数据，Docker提出了Volume的概念。简单来说，Volume就是目录或者文件，它可以绕过默认的联合文件系统，而以正常的文件或者目录的形式存在于宿主机上。

可以通过两种方式来初始化Volume：
1 在运行时使用-v来声明Volume：
docker run --name data -v /data -t -i datasong /bin/bash
#docker run -it --name mount_data -h CONTAINER -v /data datasong /bin/bash
上面的命令会将/data挂载到容器中，并绕过联合文件系统，我们可以在主机上直接操作该目录。任何在该镜像/data路径的文件将会被复制到Volume。
其中--name datasong表示挂载之后在contain中目录名，执行如下命令：
docker inspect data
结果为：
{
}
创建的数据卷可以通过docker inspect获取宿主机对应路径:

2 


（20）综合应用：搭建java集成开发环境（IDEA）：
既然docker既保证了隔离性，又可以挂载主机的目录作为可写区，那么我们可以尝试在centos7的基础上搭建完整的java IDE开发环境了。
需要注意的是，因为IDEA需要图形界面，所以有两种方式：
	1 基础镜像支持GUI显示
	2 给基础镜像安装GUI支持
否则无法正确的启动IDEA，这个教程只是简单的一个综合演示，不一定有实际使用价值。
因为我们的出发点是官方的centos-base，所以自带GUI支持显然是不可能的。那么我们就选择第二条路：搭建支持X11的镜像。

<1>本地化镜像：
因为最后我们需要使用这个镜像进行开发，那么本地化是必须的，否则无法正常使用。


<2>构建IDEA镜像：
需要的原料：
Dockerfile
jdk-8u92-linux-x64.tar.gz
ideaIC-2016.2.tar.gz
切换到这个目录，然后解压：
tar -zxf jdk-8u92-linux-x64.tar.gz -C jdk1.8.0_92/
tar -zxf ideaIC-2016.2.tar.gz -C idea2016_2/
生成了两个文件夹：
jdk1.8.0_92
idea-IC-162.1121.32
编辑Dockerfile：
{
# 设置基本的环境
FROM centos7_base
MAINTAINER hellmonky <hellmonky@qq.com> 

# 创建目录，从主机拷贝需要的文件，需要注意解压后的目录拷贝到docker中，需要指明这个文件夹的名称，否则为文件拷贝
COPY jdk1.8.0_92 /usr/local/bin/jdk1.8.0_92/
COPY idea-IC-162.1121.32 /usr/local/bin/idea-IC-162.1121.32/

# 设置环境变量
ENV JAVA_HOME=/usr/local/bin/jdk1.8.0_92
ENV CLASSPATH=.:$CLASSPTAH:$JAVA_HOME/lib
ENV PATH=$PATH:$JAVA_HOME/bin:/usr/local/bin/idea-IC-162.1121.32/bin

# 设置docker启动时候需要执行的命令
CMD ["idea.sh"]
}
然后执行docker的生成，然后运行：
docker build -t idea ide/
docker run -ti --rm -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix idea
docker run -ti --rm -e DISPLAY=:0 -v /tmp/.X11-unix:/tmp/.X11-unix firefox

docker run -ti --rm -e DISPLAY=192.168.1.161:0.0 -v /tmp/.X11-unix:/tmp/.X11-unix idea
 
	   
解析命令：
其中的『-v /tmp/.X11-unix:/tmp/.X11-unix』参数就是将主机上X11的unix套接字共享到了容器里面。因为每个unix套接字实际上就是系统/tmp/.X11-unix目录下面依据套接字编号命名的一个特殊文件。

参考文档：
http://www.infoq.com/cn/articles/talk-about-docker-running-the-chinese-gui-software









大部分时候你会需要把你host主机（宿主）上的目录映射到Container里面，这样你就非常方便地在host主机上编辑代码，然后直接就可以在Container里面运行它们，而不用手动copy到Container里面再重启Container。



（）docker实现原理：
在使用了docker到这个阶段的时候，需要回头看看docker的实现原理了。从原理出发来正确的使用docker更为重要。
docker的两大核心基础技术是namespace和cgroup，cgroup主要作资源的限制隔离，它可以限制一组进程中能使用的最大资源使用量，相对比较好理解；namespace同样可以实现资源隔离，不同的是它是通过使PID,IPC,Network等系统资源不再是全局性的，而是属于特定的Namespace实现的。每个Namespace里面的资源对其他Namespace都是透明的，这个概念有点类似于linux的多用户机制。 




（19）使用docker搭建hadoop集群：
从已经存在tar包导入docker镜像：
cat centos-7-docker.tar.xz | docker import - centos7
首先使用network命令创建一个名称为hadoop-cluster的桥接模式网络：
docker network create --driver=bridge hadoop-cluster
然后使用–net=hadoop选项，将docker容器加入到这个网络中，它们可以通过容器名称进行通信。


参考文档：
http://kiwenlau.com/2016/06/12/160612-hadoop-cluster-docker-update/


（）虚拟化的对比和分析：平台及虚拟化的差异对比
<1>硬件虚拟化：
Microsoft Hyper-V 和VMware ESX Server都是基于硬件支持的Bare-Metal虚拟化产品，他们最大的区别在于，Microsoft Hyper-V采用了微内核的结构，而ESX Server是一个单内核的产品。

单内核的主要特点是硬件的驱动程序集中在Hypervisor一层，被Hypervisor上的所有的虚机所共同使用。当一个虚机的OS需要访问硬件时，它通过Hypervisor中的driver model来访问，这种单内核的Hypervisor能够提供很好的性能，但是它在安全性和兼容性上存在缺陷。由于驱动程序和一些第三方代码跑在一个很敏感的区域内，这种模式有了一个很大的被攻击面。

设想下某些不怀好意的代码被隐藏在驱动程序当中，然后跑在Hypervisor中，这会影响到所有的客户虚拟机，而且这是很难被发现的，因为对于实际被使用的虚机来说，Hypervisor这层是不可见的，所以无法通过一些病毒软件去监控它。 另外一个问题就是稳定性，假设某个驱动程序当中存在bug，那么它将影响到所有的虚机。另外你还要求Hypervisor去支持所有的驱动程序，造成了这层体积较为庞大。所以单内核的Hypervisor一般被认为是胖Hypervisor。

而Hyper-V采用了微内核的结构，它是一个瘦Hypervisor。因为它里面没有驱动程序，所以在体积上Hyper-V更有优势，另外，由于微内核体积较小，所以运行的效率很高。驱动程序是跑在每一个分区里面的，每一个分区内的虚机OS都能够通过Hypervisor直接访问硬件，还使得每一个分区都相互独立，这样就拥有更好的安全性和稳定性。

并且微软还提供了裸机安装支持Hyper-V Server来和EXSI进行竞争。

同时，linux系统提供了Kernel-based Virtual Machine(KVM) is a virtualization infrastructure for the Linux kernel that turns it into a hypervisor. 将QEMU的CPU虚拟化使用内核处理，然后结合QEMU的外设虚拟化提供了完整的硬件虚拟化环境。
所以这种内核级别的虚拟化和上述的Microsoft Hyper-V相对应，并且由于linux内核的可剪裁，轻量化部署来抢夺VMWARE的市场，例如proxmox的虚拟化环境就可以良好的运行。

<2>容器：
上述所讨论的就是传统虚拟化的主要平台，聚焦在完整的虚拟化方案，提供内核级别的隔离支持。随着linux系统下docker的出现，应用级虚拟化的容器得到了长足的发展，对于应用的部署更加安全和方便。

目前windwos server 2016还结合docker，并且支持Dockerfile来构建docker镜像，从此windows就可以提供了两种容器：应用程序级别的容器docker和内核级别的容器Hyper-V。具体可以参考：
https://msdn.microsoft.com/zh-tw/virtualization/windowscontainers/about/about_overview

而vmware则倾向于在硬件虚拟机中提供docker支持，建立纵向的服务提供。

<3>
可以从上述内容明白，提供不同层次细化的容器是非常有必要的，应用开发人员不关心内核级别的虚拟化，内核开发人员只需要CPU的完整虚拟化，两者对于性能或者应用场景的要求是有差别的。
计算机领域遇到问题添加层是非常有效的手段，在虚拟化领域也是一样。
并且linux提供了完整的虚拟化支持，未来的发展更倾向于良好的服务集成上。


（20）关于目前正在进行的项目的企业级应用实例：
阿里云提供了OSS的文件存储服务：
https://www.aliyun.com/product/oss/
叫做对象存储服务，并且提供了基本的上传、下载、断点续传等功能，可以看作是阿里云数据中心对HDFS的一个集中应用展示，可以参考这个事情进行当前工作的指导。
这个产品比较成熟，并且借助了阿里广泛的CDN转发服务，提供了很高的使用带宽。
并且在数据存储之上做了相关的应用，比如视频转码，鉴黄，压缩等。为企业的常用场景提供了业务支持。

（21）关于kafka：
是apach下的开源分布式消息系统，和传统的消息服务RabbitMQ、Apache ActiveMQ对比具有明显的特征。

（22）关系型数据库在hadoop中的应用：Sqoop和hive
hadoop是一个技术实现，必须与业务相结合才能完成真正的大数据处理平台，两者缺一不可。但是传统型数据库在数据量非常大的情况下无法及时的完成相应的计算，导致性能下降，这个一直都是实际业务中关注的重点，也是oracle提供服务的核心。既然无法抛弃传统的关系型数据库对于数据分析应用，又需要提供数据库的处理容量，那么如何才能将关系型数据库与hadoop结合，提供良好的扩展性就成了一个非常重要的问题。

<1>Sqoop：
Apache Sqoop（SQL-to-Hadoop） 项目旨在协助 RDBMS 与 Hadoop 之间进行高效的大数据交流。用户可以在 Sqoop 的帮助下，轻松地把关系型数据库的数据导入到 Hadoop 与其相关的系统 (如HBase和Hive)中；同时也可以把数据从 Hadoop系统里抽取并导出到关系型数据库里。因此，可以说Sqoop就是一个桥梁，连接了关系型数据库与Hadoop。
<2>Hive：
hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。
Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。
<3>结合：

（23）hadoop的适用场景：
hadoop只是一个技术框架，而不是解决方案，从技术框架到解决方案是需要成本的，所以不是所有的场景都需要hadoop，对的工具和方法才能真正提高效率，为了用hadoop而用hadoop并不是一个好主意。一定要明确应用场景的特点，有针对性的选择技术方案才能做到最好。




（24）kafka的搭建和使用：
<1>环境搭建和服务启动测试：
使用CDH自己打包的kafka安装包进行安装，然后再：
cd /bin
路径下查看相关的执行命令：
[root@slave01 bin]# ll| grep kafka
lrwxrwxrwx  1 root root         28 7月  22 10:59 kafka-acls -> /etc/alternatives/kafka-acls
lrwxrwxrwx  1 root root         31 7月  22 10:59 kafka-configs -> /etc/alternatives/kafka-configs
lrwxrwxrwx  1 root root         40 7月  22 10:59 kafka-console-consumer -> /etc/alternatives/kafka-console-consumer
lrwxrwxrwx  1 root root         40 7月  22 10:59 kafka-console-producer -> /etc/alternatives/kafka-console-producer
lrwxrwxrwx  1 root root         39 7月  22 10:59 kafka-consumer-groups -> /etc/alternatives/kafka-consumer-groups
lrwxrwxrwx  1 root root         47 7月  22 10:59 kafka-consumer-offset-checker -> /etc/alternatives/kafka-consumer-offset-checker
lrwxrwxrwx  1 root root         50 7月  22 10:59 kafka-preferred-replica-election -> /etc/alternatives/kafka-preferred-replica-election
lrwxrwxrwx  1 root root         43 7月  22 10:59 kafka-reassign-partitions -> /etc/alternatives/kafka-reassign-partitions
lrwxrwxrwx  1 root root         33 7月  22 10:59 kafka-run-class -> /etc/alternatives/kafka-run-class
lrwxrwxrwx  1 root root         30 7月  22 10:59 kafka-topics -> /etc/alternatives/kafka-topics
查看当前kafka是否启动：
[root@slave01 bin]# jps
3504 NodeManager
3571 QuorumPeerMain
14644 Kafka
3508 HRegionServer
14375 Jps
3723 DataNode
4893 
显示已经启动了，可以进行测试。
在其中一个kafka的broker的节点上打开producer服务：
kafka-console-producer.sh --broker-list 192.168.1.201:9092 --topic test
然后再另一个kafka的borker节点上打开consumer服务：
kafka-console-consumer.sh --zookeeper 192.168.1.201:2181 --topic test --from-beginning
在producer服务中输入任意字符串之后，另一台机器上可以显示出这个字符串，表示接受成功。

进入kafka的一个服务节点，查看当前维护的topic：
cd /bin
kafka-topics --list --zookeeper 192.168.1.201:2181,192.168.1.202:2181,192.168.1.203:2181,192.168.1.204:2181,192.168.1.205:2181
其中:
192.168.1.201:2181,192.168.1.202:2181,192.168.1.203:2181,192.168.1.204:2181,192.168.1.205:2181
是zookeeper的服务地址。

从kafka 0.8.2.1开始可以直接删除topic，这样可以方便的进行程序的调试，下面删除名为test的topic：
kafka-topics --zookeeper 192.168.1.201:2181,192.168.1.202:2181,192.168.1.203:2181,192.168.1.204:2181,192.168.1.205:2181 --delete --topic test
然后检查当前的topic，发现已经删除了。


<2>java程序编写：
默认的kafka日志记录为info级别，这种级别方便运行，但是不方便调试，可以进入CDH，在其中的：“Kafka Broker 记录阈值”进行设置，可以修改为error来减少输出。
同时，zookeeper的日志显示也可以修改一下，设置：
Server 记录阈值
为：
ERROR


















常用linux命令：
<1>Linux中查看各文件夹大小命令：du -h --max-depth=1
具体命令格式为：
du [-abcDhHklmsSx] [-L <符号连接>][-X <文件>][--block-size][--exclude=<目录或文件>] [--max-depth=<目录层数>][--help][--version][目录或文件]
常用参数：
-a或-all 为每个指定文件显示磁盘使用情况，或者为目录中每个文件显示各自磁盘使用情况。
-b或-bytes 显示目录或文件大小时，以byte为单位。
-c或–total 除了显示目录或文件的大小外，同时也显示所有目录或文件的总和。
-D或–dereference-args 显示指定符号连接的源文件大小。
-h或–human-readable 以K，M，G为单位，提高信息的可读性。
-H或–si 与-h参数相同，但是K，M，G是以1000为换算单位,而不是以1024为换算单位。
-k或–kilobytes 以1024 bytes为单位。
-l或–count-links 重复计算硬件连接的文件。
-L<符号连接>或–dereference<符号连接> 显示选项中所指定符号连接的源文件大小。
-m或–megabytes 以1MB为单位。
-s或–summarize 仅显示总计，即当前目录的大小。
-S或–separate-dirs 显示每个目录的大小时，并不含其子目录的大小。
-x或–one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。
-X<文件>或–exclude-from=<文件> 在<文件>指定目录或文件。
–exclude=<目录或文件> 略过指定的目录或文件。
–max-depth=<目录层数> 超过指定层数的目录后，予以忽略。
–help 显示帮助。
–version 显示版本信息。







参考文档：
http://www.server-world.info/en/note?os=Ubuntu_14.04&p=initial_conf&f=2
https://linuxconfig.org/enable-ssh-root-login-on-ubuntu-16-04-xenial-xerus-linux-server-desktop
http://wiki.ubuntu.org.cn/%E6%A8%A1%E6%9D%BF:16.04source
https://codeyarns.com/2011/04/18/how-to-delete-all-lines-of-file-in-vim/
http://askubuntu.com/questions/775609/how-to-compile-ubuntu-16-04-kernel-with-zfs-module
https://wiki.ubuntu.com/Kernel/BuildYourOwnKernel
http://blog.csdn.net/jiangwei0910410003/article/details/37996723
http://jingyan.baidu.com/article/5d368d1e12a1af3f60c0570a.html
http://www.linuxidc.com/Linux/2016-05/131143.htm
http://blog.csdn.net/u010397369/article/details/41045251



